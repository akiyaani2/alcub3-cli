#!/usr/bin/env python3
"""
ALCUB3 Real-Time Security Monitoring Dashboard - Task 2.15
Patent-Pending Unified Security Operations Center with MAESTRO Integration

This module implements a comprehensive real-time security monitoring system
with <30 second anomaly detection, automated incident response, and unified
threat assessment across all MAESTRO security layers.

Key Innovations:
- Real-time security event correlation across L1-L3 layers
- Sub-30-second anomaly detection with AI-powered analysis
- Automated incident response with classification-aware escalation
- Unified threat intelligence aggregation for air-gapped operations
- Performance-optimized security operations (<100ms query response)
- Cross-layer security state synchronization

Patent Applications:
- Real-time security correlation for air-gapped AI systems
- Automated incident response with classification escalation
- Performance-optimized security monitoring infrastructure
"""

import asyncio
import time
import json
import threading
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Callable
from enum import Enum
from dataclasses import dataclass, asdict
from collections import defaultdict, deque
import statistics
import logging
from pathlib import Path

# Import MAESTRO security components
from shared.classification import ClassificationLevel, classify_content
from shared.threat_detector import ThreatDetector, ThreatIndicator, ThreatLevel
from l1_foundation.model_security import ModelSecurityValidator
from l2_data.data_operations import SecureDataOperations
from l3_agent.agent_sandboxing import AgentSandboxingSystem

class SecurityEventType(Enum):
    """Types of security events monitored by the dashboard."""
    THREAT_DETECTED = "threat_detected"
    CLASSIFICATION_VIOLATION = "classification_violation"
    AUTHENTICATION_FAILURE = "authentication_failure"
    SANDBOX_BREACH = "sandbox_breach"
    PERFORMANCE_ANOMALY = "performance_anomaly"
    PROMPT_INJECTION = "prompt_injection"
    ADVERSARIAL_INPUT = "adversarial_input"
    NETWORK_INTRUSION = "network_intrusion"
    SYSTEM_COMPROMISE = "system_compromise"
    COMPLIANCE_VIOLATION = "compliance_violation"

class SeverityLevel(Enum):
    """Security event severity levels."""
    CRITICAL = "critical"      # Immediate response required
    HIGH = "high"             # Response within 5 minutes
    MEDIUM = "medium"         # Response within 30 minutes
    LOW = "low"              # Response within 24 hours
    INFO = "info"            # Informational only

class IncidentStatus(Enum):
    """Incident response status tracking."""
    ACTIVE = "active"
    INVESTIGATING = "investigating"
    CONTAINED = "contained"
    RESOLVED = "resolved"
    CLOSED = "closed"

@dataclass
class SecurityEvent:
    """Structured security event representation."""
    event_id: str
    event_type: SecurityEventType
    severity: SeverityLevel
    classification_level: ClassificationLevel
    timestamp: datetime
    source_component: str
    source_layer: str
    description: str
    details: Dict[str, Any]
    indicators: List[ThreatIndicator]
    affected_systems: List[str]
    correlation_id: Optional[str] = None
    response_actions: List[str] = None
    incident_id: Optional[str] = None
    
    def __post_init__(self):
        if self.response_actions is None:
            self.response_actions = []

@dataclass
class SecurityIncident:
    """Security incident tracking and management."""
    incident_id: str
    title: str
    status: IncidentStatus
    severity: SeverityLevel
    classification_level: ClassificationLevel
    created_at: datetime
    updated_at: datetime
    assigned_to: str
    events: List[SecurityEvent]
    timeline: List[Dict[str, Any]]
    containment_actions: List[str]
    resolution_summary: Optional[str] = None
    lessons_learned: Optional[str] = None
    
    def add_event(self, event: SecurityEvent):
        """Add security event to incident."""
        event.incident_id = self.incident_id
        self.events.append(event)
        self.updated_at = datetime.utcnow()
        
        # Update incident severity if event is more severe
        severity_order = {
            SeverityLevel.INFO: 0,
            SeverityLevel.LOW: 1,
            SeverityLevel.MEDIUM: 2,
            SeverityLevel.HIGH: 3,
            SeverityLevel.CRITICAL: 4
        }
        
        if severity_order[event.severity] > severity_order[self.severity]:
            self.severity = event.severity

@dataclass
class SecurityMetrics:
    """Real-time security metrics and statistics."""
    total_events: int
    events_by_severity: Dict[str, int]
    events_by_type: Dict[str, int]
    events_by_layer: Dict[str, int]
    active_incidents: int
    threat_detection_rate: float
    false_positive_rate: float
    average_response_time: float
    system_availability: float
    compliance_score: float
    last_updated: datetime

class SecurityCorrelationEngine:
    """Advanced security event correlation and pattern detection."""
    
    def __init__(self, correlation_window: int = 300):
        self.correlation_window = correlation_window  # 5 minutes
        self.event_buffer = deque(maxlen=10000)
        self.correlation_rules = self._load_correlation_rules()
        self.pattern_cache = {}
        
    def _load_correlation_rules(self) -> Dict[str, Any]:
        """Load security correlation rules and patterns."""
        return {
            "authentication_failures": {
                "threshold": 5,
                "window": 60,  # 1 minute
                "severity": SeverityLevel.HIGH,
                "actions": ["block_source", "alert_security_team"]
            },
            "prompt_injection_patterns": {
                "threshold": 3,
                "window": 30,  # 30 seconds
                "severity": SeverityLevel.CRITICAL,
                "actions": ["isolate_session", "emergency_alert"]
            },
            "classification_violations": {
                "threshold": 2,
                "window": 60,
                "severity": SeverityLevel.CRITICAL,
                "actions": ["audit_access", "escalate_to_admin"]
            },
            "cross_layer_attacks": {
                "layers": ["l1_foundation", "l2_data", "l3_agent"],
                "threshold": 2,
                "window": 120,
                "severity": SeverityLevel.CRITICAL,
                "actions": ["system_lockdown", "incident_response"]
            }
        }
    
    def correlate_events(self, events: List[SecurityEvent]) -> List[Dict[str, Any]]:
        """Identify correlated security events and patterns."""
        correlations = []
        
        for event in events:
            self.event_buffer.append(event)
        
        # Apply correlation rules
        for rule_name, rule_config in self.correlation_rules.items():
            correlation = self._apply_correlation_rule(rule_name, rule_config)
            if correlation:
                correlations.append(correlation)
        
        return correlations
    
    def _apply_correlation_rule(self, rule_name: str, rule_config: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Apply specific correlation rule to event buffer."""
        current_time = datetime.utcnow()
        window_start = current_time - timedelta(seconds=rule_config["window"])
        
        # Filter events within time window
        relevant_events = [
            event for event in self.event_buffer
            if event.timestamp >= window_start
        ]
        
        if rule_name == "authentication_failures":
            return self._check_authentication_pattern(relevant_events, rule_config)
        elif rule_name == "prompt_injection_patterns":
            return self._check_prompt_injection_pattern(relevant_events, rule_config)
        elif rule_name == "classification_violations":
            return self._check_classification_pattern(relevant_events, rule_config)
        elif rule_name == "cross_layer_attacks":
            return self._check_cross_layer_pattern(relevant_events, rule_config)
        
        return None
    
    def _check_authentication_pattern(self, events: List[SecurityEvent], rule_config: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Check for authentication failure patterns."""
        auth_failures = [
            event for event in events
            if event.event_type == SecurityEventType.AUTHENTICATION_FAILURE
        ]
        
        if len(auth_failures) >= rule_config["threshold"]:
            return {
                "type": "authentication_attack",
                "severity": rule_config["severity"],
                "events": auth_failures,
                "actions": rule_config["actions"],
                "description": f"Detected {len(auth_failures)} authentication failures in {rule_config['window']} seconds"
            }
        
        return None
    
    def _check_prompt_injection_pattern(self, events: List[SecurityEvent], rule_config: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Check for prompt injection attack patterns."""
        injection_events = [
            event for event in events
            if event.event_type == SecurityEventType.PROMPT_INJECTION
        ]
        
        if len(injection_events) >= rule_config["threshold"]:
            return {
                "type": "prompt_injection_attack",
                "severity": rule_config["severity"],
                "events": injection_events,
                "actions": rule_config["actions"],
                "description": f"Detected {len(injection_events)} prompt injection attempts in {rule_config['window']} seconds"
            }
        
        return None
    
    def _check_classification_pattern(self, events: List[SecurityEvent], rule_config: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Check for classification violation patterns."""
        classification_events = [
            event for event in events
            if event.event_type == SecurityEventType.CLASSIFICATION_VIOLATION
        ]
        
        if len(classification_events) >= rule_config["threshold"]:
            return {
                "type": "classification_breach",
                "severity": rule_config["severity"],
                "events": classification_events,
                "actions": rule_config["actions"],
                "description": f"Detected {len(classification_events)} classification violations in {rule_config['window']} seconds"
            }
        
        return None
    
    def _check_cross_layer_pattern(self, events: List[SecurityEvent], rule_config: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Check for cross-layer attack patterns."""
        layer_events = defaultdict(list)
        
        for event in events:
            layer_events[event.source_layer].append(event)
        
        # Check if attacks span multiple MAESTRO layers
        attacked_layers = [
            layer for layer in rule_config["layers"]
            if len(layer_events[layer]) > 0
        ]
        
        if len(attacked_layers) >= rule_config["threshold"]:
            all_events = []
            for layer in attacked_layers:
                all_events.extend(layer_events[layer])
            
            return {
                "type": "cross_layer_attack",
                "severity": rule_config["severity"],
                "events": all_events,
                "actions": rule_config["actions"],
                "description": f"Detected coordinated attack across {len(attacked_layers)} MAESTRO layers"
            }
        
        return None

class IncidentResponseEngine:
    """Automated incident response and escalation system."""
    
    def __init__(self, dashboard):
        self.dashboard = dashboard
        self.response_actions = self._load_response_actions()
        self.escalation_rules = self._load_escalation_rules()
        
    def _load_response_actions(self) -> Dict[str, Callable]:
        """Load automated response action functions."""
        return {
            "block_source": self._block_source,
            "alert_security_team": self._alert_security_team,
            "isolate_session": self._isolate_session,
            "emergency_alert": self._emergency_alert,
            "audit_access": self._audit_access,
            "escalate_to_admin": self._escalate_to_admin,
            "system_lockdown": self._system_lockdown,
            "incident_response": self._incident_response
        }
    
    def _load_escalation_rules(self) -> Dict[str, Any]:
        """Load incident escalation rules."""
        return {
            SeverityLevel.CRITICAL: {
                "response_time": 60,  # 1 minute
                "escalation_chain": ["security_team", "ciso", "cto"],
                "actions": ["immediate_containment", "executive_notification"]
            },
            SeverityLevel.HIGH: {
                "response_time": 300,  # 5 minutes
                "escalation_chain": ["security_team", "security_manager"],
                "actions": ["containment", "investigation"]
            },
            SeverityLevel.MEDIUM: {
                "response_time": 1800,  # 30 minutes
                "escalation_chain": ["security_analyst"],
                "actions": ["investigation", "monitoring"]
            },
            SeverityLevel.LOW: {
                "response_time": 86400,  # 24 hours
                "escalation_chain": ["security_analyst"],
                "actions": ["logging", "trend_analysis"]
            }
        }
    
    async def respond_to_incident(self, incident: SecurityIncident) -> Dict[str, Any]:
        """Execute automated response to security incident."""
        response_log = {
            "incident_id": incident.incident_id,
            "response_timestamp": datetime.utcnow(),
            "actions_taken": [],
            "escalations": [],
            "status": "processing"
        }
        
        try:
            # Execute automated response actions
            for event in incident.events:
                for action_name in event.response_actions:
                    if action_name in self.response_actions:
                        action_result = await self._execute_action(action_name, event)
                        response_log["actions_taken"].append({
                            "action": action_name,
                            "event_id": event.event_id,
                            "result": action_result,
                            "timestamp": datetime.utcnow()
                        })
            
            # Handle escalation if required
            escalation_rule = self.escalation_rules.get(incident.severity)
            if escalation_rule:
                escalation_result = await self._handle_escalation(incident, escalation_rule)
                response_log["escalations"].append(escalation_result)
            
            response_log["status"] = "completed"
            
        except Exception as e:
            response_log["status"] = "failed"
            response_log["error"] = str(e)
            self.dashboard.logger.error(f"Incident response failed: {e}")
        
        return response_log
    
    async def _execute_action(self, action_name: str, event: SecurityEvent) -> Dict[str, Any]:
        """Execute specific response action."""
        action_func = self.response_actions[action_name]
        return await action_func(event)
    
    async def _handle_escalation(self, incident: SecurityIncident, escalation_rule: Dict[str, Any]) -> Dict[str, Any]:
        """Handle incident escalation according to rules."""
        escalation_log = {
            "escalation_timestamp": datetime.utcnow(),
            "severity": incident.severity.value,
            "escalation_chain": escalation_rule["escalation_chain"],
            "notifications_sent": [],
            "status": "processing"
        }
        
        try:
            # Send notifications to escalation chain
            for recipient in escalation_rule["escalation_chain"]:
                notification_result = await self._send_notification(incident, recipient)
                escalation_log["notifications_sent"].append({
                    "recipient": recipient,
                    "result": notification_result,
                    "timestamp": datetime.utcnow()
                })
            
            escalation_log["status"] = "completed"
            
        except Exception as e:
            escalation_log["status"] = "failed"
            escalation_log["error"] = str(e)
        
        return escalation_log
    
    async def _send_notification(self, incident: SecurityIncident, recipient: str) -> Dict[str, Any]:
        """Send incident notification to recipient."""
        # In production, this would integrate with actual notification systems
        notification = {
            "recipient": recipient,
            "incident_id": incident.incident_id,
            "severity": incident.severity.value,
            "classification": incident.classification_level.value,
            "summary": incident.title,
            "timestamp": datetime.utcnow(),
            "status": "sent"
        }
        
        self.dashboard.logger.info(f"Notification sent to {recipient} for incident {incident.incident_id}")
        return notification
    
    # Response action implementations
    async def _block_source(self, event: SecurityEvent) -> Dict[str, Any]:
        """Block source of security threat."""
        # Implementation would integrate with network security controls
        return {"action": "block_source", "status": "simulated", "source": event.details.get("source_ip", "unknown")}
    
    async def _alert_security_team(self, event: SecurityEvent) -> Dict[str, Any]:
        """Alert security team of threat."""
        return {"action": "alert_security_team", "status": "simulated", "event_id": event.event_id}
    
    async def _isolate_session(self, event: SecurityEvent) -> Dict[str, Any]:
        """Isolate compromised session."""
        return {"action": "isolate_session", "status": "simulated", "session_id": event.details.get("session_id", "unknown")}
    
    async def _emergency_alert(self, event: SecurityEvent) -> Dict[str, Any]:
        """Send emergency security alert."""
        return {"action": "emergency_alert", "status": "simulated", "severity": "critical"}
    
    async def _audit_access(self, event: SecurityEvent) -> Dict[str, Any]:
        """Trigger access audit."""
        return {"action": "audit_access", "status": "simulated", "user_id": event.details.get("user_id", "unknown")}
    
    async def _escalate_to_admin(self, event: SecurityEvent) -> Dict[str, Any]:
        """Escalate to system administrator."""
        return {"action": "escalate_to_admin", "status": "simulated", "admin_notified": True}
    
    async def _system_lockdown(self, event: SecurityEvent) -> Dict[str, Any]:
        """Initiate system lockdown procedure."""
        return {"action": "system_lockdown", "status": "simulated", "lockdown_level": "partial"}
    
    async def _incident_response(self, event: SecurityEvent) -> Dict[str, Any]:
        """Trigger formal incident response."""
        return {"action": "incident_response", "status": "simulated", "ir_team_notified": True}

class SecurityMonitoringDashboard:
    """
    Real-Time Security Monitoring Dashboard - ALCUB3 Task 2.15
    
    Comprehensive security operations center with real-time monitoring,
    automated threat detection, and incident response capabilities.
    """
    
    def __init__(self, config_path: Optional[str] = None):
        """Initialize security monitoring dashboard."""
        self.config = self._load_config(config_path)
        self.logger = self._setup_logging()
        
        # Core components
        self.threat_detector = ThreatDetector()
        self.model_security = ModelSecurityValidator()
        self.data_operations = SecureDataOperations()
        self.agent_sandboxing = AgentSandboxingSystem()
        
        # Dashboard components
        self.correlation_engine = SecurityCorrelationEngine()
        self.incident_response = IncidentResponseEngine(self)
        
        # State management
        self.events = deque(maxlen=50000)  # Keep last 50k events
        self.active_incidents = {}
        self.metrics = SecurityMetrics(
            total_events=0,
            events_by_severity={},
            events_by_type={},
            events_by_layer={},
            active_incidents=0,
            threat_detection_rate=0.0,
            false_positive_rate=0.0,
            average_response_time=0.0,
            system_availability=100.0,
            compliance_score=100.0,
            last_updated=datetime.utcnow()
        )
        
        # Performance tracking
        self.performance_metrics = {
            "event_processing_times": deque(maxlen=1000),
            "query_response_times": deque(maxlen=1000),
            "anomaly_detection_times": deque(maxlen=1000),
            "incident_response_times": deque(maxlen=100)
        }
        
        # Monitoring state
        self.is_running = False
        self.monitoring_tasks = []
        
        self.logger.info("Security Monitoring Dashboard initialized")
    
    def _load_config(self, config_path: Optional[str]) -> Dict[str, Any]:
        """Load dashboard configuration."""
        default_config = {
            "monitoring": {
                "event_buffer_size": 50000,
                "correlation_window": 300,
                "anomaly_threshold": 0.95,
                "performance_target_ms": 100
            },
            "alerts": {
                "notification_channels": ["email", "sms", "webhook"],
                "escalation_timeout": 300,
                "max_notifications_per_hour": 100
            },
            "security": {
                "classification_enforcement": True,
                "audit_all_events": True,
                "secure_storage": True,
                "retention_days": 90
            },
            "performance": {
                "max_query_time_ms": 100,
                "max_event_processing_time_ms": 50,
                "max_anomaly_detection_time_ms": 30000
            }
        }
        
        if config_path and Path(config_path).exists():
            try:
                with open(config_path, 'r') as f:
                    user_config = json.load(f)
                # Merge user config with defaults
                default_config.update(user_config)
            except Exception as e:
                logging.warning(f"Failed to load config from {config_path}: {e}")
        
        return default_config
    
    def _setup_logging(self) -> logging.Logger:
        """Setup dashboard logging."""
        logger = logging.getLogger("security_dashboard")
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    async def start_monitoring(self):
        """Start real-time security monitoring."""
        if self.is_running:
            self.logger.warning("Monitoring already running")
            return
        
        self.is_running = True
        self.logger.info("Starting security monitoring dashboard")
        
        # Start monitoring tasks
        self.monitoring_tasks = [
            asyncio.create_task(self._monitor_security_events()),
            asyncio.create_task(self._monitor_performance_metrics()),
            asyncio.create_task(self._monitor_system_health()),
            asyncio.create_task(self._process_incident_queue()),
            asyncio.create_task(self._update_dashboard_metrics())
        ]
        
        # Wait for all tasks
        try:
            await asyncio.gather(*self.monitoring_tasks)
        except asyncio.CancelledError:
            self.logger.info("Monitoring tasks cancelled")
        except Exception as e:
            self.logger.error(f"Monitoring error: {e}")
        finally:
            self.is_running = False
    
    async def stop_monitoring(self):
        """Stop security monitoring."""
        if not self.is_running:
            return
        
        self.logger.info("Stopping security monitoring dashboard")
        self.is_running = False
        
        # Cancel all monitoring tasks
        for task in self.monitoring_tasks:
            task.cancel()
        
        # Wait for tasks to complete
        await asyncio.gather(*self.monitoring_tasks, return_exceptions=True)
        
        self.logger.info("Security monitoring stopped")
    
    async def _monitor_security_events(self):
        """Monitor and process security events in real-time."""
        while self.is_running:
            try:
                # Simulate event collection from MAESTRO components
                await self._collect_security_events()
                await asyncio.sleep(1)  # Check every second
                
            except Exception as e:
                self.logger.error(f"Error monitoring security events: {e}")
                await asyncio.sleep(5)
    
    async def _collect_security_events(self):
        """Collect security events from all MAESTRO layers."""
        start_time = time.time()
        
        # Collect events from each layer
        l1_events = await self._collect_l1_events()
        l2_events = await self._collect_l2_events()
        l3_events = await self._collect_l3_events()
        
        all_events = l1_events + l2_events + l3_events
        
        # Process and correlate events
        if all_events:
            correlations = self.correlation_engine.correlate_events(all_events)
            
            # Create incidents from correlations
            for correlation in correlations:
                await self._create_incident_from_correlation(correlation)
            
            # Add events to dashboard
            for event in all_events:
                await self.add_security_event(event)
        
        # Track performance
        processing_time = (time.time() - start_time) * 1000
        self.performance_metrics["event_processing_times"].append(processing_time)
    
    async def _collect_l1_events(self) -> List[SecurityEvent]:
        """Collect events from L1 Foundation layer."""
        events = []
        
        # Simulate L1 security events
        # In production, this would interface with actual L1 components
        if hasattr(self.model_security, 'get_recent_events'):
            l1_events = self.model_security.get_recent_events()
            for event_data in l1_events:
                event = SecurityEvent(
                    event_id=f"l1_{int(time.time() * 1000000)}",
                    event_type=SecurityEventType.PROMPT_INJECTION,
                    severity=SeverityLevel.HIGH,
                    classification_level=ClassificationLevel.UNCLASSIFIED,
                    timestamp=datetime.utcnow(),
                    source_component="model_security",
                    source_layer="l1_foundation",
                    description="L1 Foundation security event",
                    details=event_data,
                    indicators=[],
                    affected_systems=["foundation_model"]
                )
                events.append(event)
        
        return events
    
    async def _collect_l2_events(self) -> List[SecurityEvent]:
        """Collect events from L2 Data layer."""
        events = []
        
        # Simulate L2 security events
        if hasattr(self.data_operations, 'get_recent_events'):
            l2_events = self.data_operations.get_recent_events()
            for event_data in l2_events:
                event = SecurityEvent(
                    event_id=f"l2_{int(time.time() * 1000000)}",
                    event_type=SecurityEventType.CLASSIFICATION_VIOLATION,
                    severity=SeverityLevel.CRITICAL,
                    classification_level=ClassificationLevel.SECRET,
                    timestamp=datetime.utcnow(),
                    source_component="data_operations",
                    source_layer="l2_data",
                    description="L2 Data security event",
                    details=event_data,
                    indicators=[],
                    affected_systems=["data_storage", "classification_engine"]
                )
                events.append(event)
        
        return events
    
    async def _collect_l3_events(self) -> List[SecurityEvent]:
        """Collect events from L3 Agent layer."""
        events = []
        
        # Simulate L3 security events
        if hasattr(self.agent_sandboxing, 'get_recent_events'):
            l3_events = self.agent_sandboxing.get_recent_events()
            for event_data in l3_events:
                event = SecurityEvent(
                    event_id=f"l3_{int(time.time() * 1000000)}",
                    event_type=SecurityEventType.SANDBOX_BREACH,
                    severity=SeverityLevel.CRITICAL,
                    classification_level=ClassificationLevel.TOP_SECRET,
                    timestamp=datetime.utcnow(),
                    source_component="agent_sandboxing",
                    source_layer="l3_agent",
                    description="L3 Agent security event",
                    details=event_data,
                    indicators=[],
                    affected_systems=["agent_sandbox", "integrity_validator"]
                )
                events.append(event)
        
        return events
    
    async def _create_incident_from_correlation(self, correlation: Dict[str, Any]):
        """Create security incident from correlated events."""
        incident_id = f"inc_{int(time.time() * 1000000)}"
        
        # Determine highest classification level from events
        classification_levels = [event.classification_level for event in correlation["events"]]
        max_classification = max(classification_levels, key=lambda x: x.numeric_level)
        
        incident = SecurityIncident(
            incident_id=incident_id,
            title=f"{correlation['type']}: {correlation['description']}",
            status=IncidentStatus.ACTIVE,
            severity=correlation["severity"],
            classification_level=max_classification,
            created_at=datetime.utcnow(),
            updated_at=datetime.utcnow(),
            assigned_to="security_team",
            events=correlation["events"],
            timeline=[{
                "timestamp": datetime.utcnow(),
                "action": "incident_created",
                "description": "Incident created from event correlation",
                "actor": "correlation_engine"
            }],
            containment_actions=correlation["actions"]
        )
        
        # Add to active incidents
        self.active_incidents[incident_id] = incident
        
        # Trigger automated response
        response_log = await self.incident_response.respond_to_incident(incident)
        
        incident.timeline.append({
            "timestamp": datetime.utcnow(),
            "action": "automated_response",
            "description": f"Automated response executed: {response_log['status']}",
            "actor": "incident_response_engine",
            "details": response_log
        })
        
        self.logger.warning(f"Created incident {incident_id}: {incident.title}")
    
    async def add_security_event(self, event: SecurityEvent):
        """Add security event to dashboard."""
        start_time = time.time()
        
        # Add to events buffer
        self.events.append(event)
        
        # Update metrics
        await self._update_event_metrics(event)
        
        # Check for anomalies
        anomaly_detected = await self._detect_anomalies(event)
        if anomaly_detected:
            self.logger.warning(f"Anomaly detected in event {event.event_id}")
        
        # Track performance
        processing_time = (time.time() - start_time) * 1000
        self.performance_metrics["event_processing_times"].append(processing_time)
        
        # Log high-severity events
        if event.severity in [SeverityLevel.CRITICAL, SeverityLevel.HIGH]:
            self.logger.warning(f"High-severity event: {event.event_type.value} - {event.description}")
    
    async def _update_event_metrics(self, event: SecurityEvent):
        """Update dashboard metrics with new event."""
        self.metrics.total_events += 1
        
        # Update severity distribution
        severity_key = event.severity.value
        self.metrics.events_by_severity[severity_key] = self.metrics.events_by_severity.get(severity_key, 0) + 1
        
        # Update event type distribution
        type_key = event.event_type.value
        self.metrics.events_by_type[type_key] = self.metrics.events_by_type.get(type_key, 0) + 1
        
        # Update layer distribution
        layer_key = event.source_layer
        self.metrics.events_by_layer[layer_key] = self.metrics.events_by_layer.get(layer_key, 0) + 1
        
        # Update active incidents count
        self.metrics.active_incidents = len(self.active_incidents)
        
        self.metrics.last_updated = datetime.utcnow()
    
    async def _detect_anomalies(self, event: SecurityEvent) -> bool:
        """Detect anomalies in security events using AI analysis."""
        start_time = time.time()
        
        try:
            # Implement anomaly detection logic
            # This is a simplified version - production would use ML models
            
            # Check event frequency anomalies
            recent_events = [
                e for e in self.events
                if e.timestamp >= datetime.utcnow() - timedelta(minutes=5)
                and e.event_type == event.event_type
            ]
            
            # Calculate baseline frequency
            baseline_frequency = len([
                e for e in self.events
                if e.timestamp >= datetime.utcnow() - timedelta(hours=1)
                and e.event_type == event.event_type
            ]) / 12  # Events per 5-minute window in last hour
            
            current_frequency = len(recent_events)
            
            # Anomaly if current frequency is 3x baseline
            anomaly_detected = current_frequency > baseline_frequency * 3
            
            # Track performance
            detection_time = (time.time() - start_time) * 1000
            self.performance_metrics["anomaly_detection_times"].append(detection_time)
            
            return anomaly_detected
            
        except Exception as e:
            self.logger.error(f"Anomaly detection error: {e}")
            return False
    
    async def _monitor_performance_metrics(self):
        """Monitor dashboard performance metrics."""
        while self.is_running:
            try:
                # Calculate average response times
                if self.performance_metrics["query_response_times"]:
                    avg_query_time = statistics.mean(self.performance_metrics["query_response_times"])
                    self.metrics.average_response_time = avg_query_time
                
                # Check performance thresholds
                max_query_time = self.config["performance"]["max_query_time_ms"]
                if avg_query_time > max_query_time:
                    self.logger.warning(f"Query response time exceeds threshold: {avg_query_time:.2f}ms > {max_query_time}ms")
                
                await asyncio.sleep(30)  # Check every 30 seconds
                
            except Exception as e:
                self.logger.error(f"Error monitoring performance: {e}")
                await asyncio.sleep(30)
    
    async def _monitor_system_health(self):
        """Monitor overall system health and availability."""
        while self.is_running:
            try:
                # Check component health
                health_checks = {
                    "threat_detector": await self._check_component_health(self.threat_detector),
                    "model_security": await self._check_component_health(self.model_security),
                    "data_operations": await self._check_component_health(self.data_operations),
                    "agent_sandboxing": await self._check_component_health(self.agent_sandboxing)
                }
                
                # Calculate system availability
                healthy_components = sum(1 for health in health_checks.values() if health)
                total_components = len(health_checks)
                availability = (healthy_components / total_components) * 100
                
                self.metrics.system_availability = availability
                
                # Alert if availability drops
                if availability < 95.0:
                    self.logger.error(f"System availability degraded: {availability:.1f}%")
                
                await asyncio.sleep(60)  # Check every minute
                
            except Exception as e:
                self.logger.error(f"Error monitoring system health: {e}")
                await asyncio.sleep(60)
    
    async def _check_component_health(self, component) -> bool:
        """Check health of individual component."""
        try:
            # Check if component has health check method
            if hasattr(component, 'health_check'):
                return await component.health_check()
            else:
                # Basic health check - component exists and is accessible
                return component is not None
        except Exception:
            return False
    
    async def _process_incident_queue(self):
        """Process active incidents and update their status."""
        while self.is_running:
            try:
                current_time = datetime.utcnow()
                
                for incident_id, incident in list(self.active_incidents.items()):
                    # Check if incident needs escalation
                    time_since_created = (current_time - incident.created_at).total_seconds()
                    
                    # Auto-resolve low severity incidents after 24 hours
                    if (incident.severity == SeverityLevel.LOW and 
                        time_since_created > 86400 and 
                        incident.status == IncidentStatus.ACTIVE):
                        
                        incident.status = IncidentStatus.RESOLVED
                        incident.resolution_summary = "Auto-resolved after 24 hours"
                        incident.updated_at = current_time
                        
                        incident.timeline.append({
                            "timestamp": current_time,
                            "action": "auto_resolved",
                            "description": "Incident auto-resolved after 24 hours",
                            "actor": "dashboard_automation"
                        })
                        
                        self.logger.info(f"Auto-resolved incident {incident_id}")
                
                # Remove resolved incidents from active list
                resolved_incidents = [
                    incident_id for incident_id, incident in self.active_incidents.items()
                    if incident.status in [IncidentStatus.RESOLVED, IncidentStatus.CLOSED]
                ]
                
                for incident_id in resolved_incidents:
                    del self.active_incidents[incident_id]
                
                await asyncio.sleep(300)  # Check every 5 minutes
                
            except Exception as e:
                self.logger.error(f"Error processing incident queue: {e}")
                await asyncio.sleep(300)
    
    async def _update_dashboard_metrics(self):
        """Update dashboard metrics and statistics."""
        while self.is_running:
            try:
                # Calculate threat detection rate
                total_threats = len([
                    e for e in self.events
                    if e.event_type in [SecurityEventType.THREAT_DETECTED, SecurityEventType.PROMPT_INJECTION]
                ])
                
                if self.metrics.total_events > 0:
                    self.metrics.threat_detection_rate = (total_threats / self.metrics.total_events) * 100
                
                # Calculate false positive rate (simulated)
                # In production, this would be based on confirmed threat analysis
                self.metrics.false_positive_rate = 5.0  # Simulate 5% false positive rate
                
                # Calculate compliance score
                # Based on successful security validations and policy adherence
                compliance_events = len([
                    e for e in self.events
                    if e.event_type != SecurityEventType.COMPLIANCE_VIOLATION
                ])
                
                if self.metrics.total_events > 0:
                    self.metrics.compliance_score = (compliance_events / self.metrics.total_events) * 100
                
                self.metrics.last_updated = datetime.utcnow()
                
                await asyncio.sleep(60)  # Update every minute
                
            except Exception as e:
                self.logger.error(f"Error updating dashboard metrics: {e}")
                await asyncio.sleep(60)
    
    # Public API methods
    
    async def get_security_metrics(self) -> Dict[str, Any]:
        """Get current security metrics."""
        start_time = time.time()
        
        metrics_dict = asdict(self.metrics)
        
        # Add performance statistics
        if self.performance_metrics["event_processing_times"]:
            metrics_dict["performance"] = {
                "avg_event_processing_time_ms": statistics.mean(self.performance_metrics["event_processing_times"]),
                "avg_query_response_time_ms": statistics.mean(self.performance_metrics["query_response_times"]) if self.performance_metrics["query_response_times"] else 0,
                "avg_anomaly_detection_time_ms": statistics.mean(self.performance_metrics["anomaly_detection_times"]) if self.performance_metrics["anomaly_detection_times"] else 0
            }
        
        # Track query performance
        query_time = (time.time() - start_time) * 1000
        self.performance_metrics["query_response_times"].append(query_time)
        
        return metrics_dict
    
    async def get_recent_events(self, limit: int = 100, severity_filter: Optional[SeverityLevel] = None, 
                               event_type_filter: Optional[SecurityEventType] = None) -> List[Dict[str, Any]]:
        """Get recent security events with optional filtering."""
        start_time = time.time()
        
        # Filter events
        filtered_events = list(self.events)
        
        if severity_filter:
            filtered_events = [e for e in filtered_events if e.severity == severity_filter]
        
        if event_type_filter:
            filtered_events = [e for e in filtered_events if e.event_type == event_type_filter]
        
        # Sort by timestamp (most recent first)
        filtered_events.sort(key=lambda x: x.timestamp, reverse=True)
        
        # Limit results
        limited_events = filtered_events[:limit]
        
        # Convert to dictionaries
        events_dict = [asdict(event) for event in limited_events]
        
        # Track query performance
        query_time = (time.time() - start_time) * 1000
        self.performance_metrics["query_response_times"].append(query_time)
        
        return events_dict
    
    async def get_active_incidents(self) -> List[Dict[str, Any]]:
        """Get current active incidents."""
        start_time = time.time()
        
        incidents_dict = [asdict(incident) for incident in self.active_incidents.values()]
        
        # Track query performance
        query_time = (time.time() - start_time) * 1000
        self.performance_metrics["query_response_times"].append(query_time)
        
        return incidents_dict
    
    async def get_incident_details(self, incident_id: str) -> Optional[Dict[str, Any]]:
        """Get detailed information about specific incident."""
        start_time = time.time()
        
        incident = self.active_incidents.get(incident_id)
        if incident:
            incident_dict = asdict(incident)
        else:
            incident_dict = None
        
        # Track query performance
        query_time = (time.time() - start_time) * 1000
        self.performance_metrics["query_response_times"].append(query_time)
        
        return incident_dict
    
    async def get_threat_intelligence(self) -> Dict[str, Any]:
        """Get current threat intelligence summary."""
        start_time = time.time()
        
        # Analyze recent threats
        recent_events = [
            e for e in self.events
            if e.timestamp >= datetime.utcnow() - timedelta(hours=24)
        ]
        
        threat_summary = {
            "total_threats_24h": len(recent_events),
            "threat_types": {},
            "severity_distribution": {},
            "affected_systems": set(),
            "top_indicators": [],
            "threat_trends": self._calculate_threat_trends()
        }
        
        for event in recent_events:
            # Count threat types
            threat_type = event.event_type.value
            threat_summary["threat_types"][threat_type] = threat_summary["threat_types"].get(threat_type, 0) + 1
            
            # Count severity levels
            severity = event.severity.value
            threat_summary["severity_distribution"][severity] = threat_summary["severity_distribution"].get(severity, 0) + 1
            
            # Track affected systems
            threat_summary["affected_systems"].update(event.affected_systems)
        
        # Convert set to list for JSON serialization
        threat_summary["affected_systems"] = list(threat_summary["affected_systems"])
        
        # Track query performance
        query_time = (time.time() - start_time) * 1000
        self.performance_metrics["query_response_times"].append(query_time)
        
        return threat_summary
    
    def _calculate_threat_trends(self) -> Dict[str, Any]:
        """Calculate threat trends over time."""
        # Simplified trend calculation
        current_hour_events = len([
            e for e in self.events
            if e.timestamp >= datetime.utcnow() - timedelta(hours=1)
        ])
        
        previous_hour_events = len([
            e for e in self.events
            if e.timestamp >= datetime.utcnow() - timedelta(hours=2)
            and e.timestamp < datetime.utcnow() - timedelta(hours=1)
        ])
        
        if previous_hour_events > 0:
            trend_percentage = ((current_hour_events - previous_hour_events) / previous_hour_events) * 100
        else:
            trend_percentage = 0 if current_hour_events == 0 else 100
        
        return {
            "current_hour_events": current_hour_events,
            "previous_hour_events": previous_hour_events,
            "trend_percentage": round(trend_percentage, 2),
            "trend_direction": "increasing" if trend_percentage > 0 else "decreasing" if trend_percentage < 0 else "stable"
        }
    
    async def export_security_report(self, format_type: str = "json", timeframe_hours: int = 24) -> Dict[str, Any]:
        """Export comprehensive security report."""
        start_time = time.time()
        
        # Filter events by timeframe
        cutoff_time = datetime.utcnow() - timedelta(hours=timeframe_hours)
        timeframe_events = [e for e in self.events if e.timestamp >= cutoff_time]
        
        report = {
            "report_metadata": {
                "generated_at": datetime.utcnow().isoformat(),
                "timeframe_hours": timeframe_hours,
                "format": format_type,
                "total_events": len(timeframe_events)
            },
            "executive_summary": {
                "total_incidents": len(self.active_incidents),
                "critical_events": len([e for e in timeframe_events if e.severity == SeverityLevel.CRITICAL]),
                "high_events": len([e for e in timeframe_events if e.severity == SeverityLevel.HIGH]),
                "system_availability": self.metrics.system_availability,
                "compliance_score": self.metrics.compliance_score
            },
            "detailed_metrics": asdict(self.metrics),
            "incident_summary": [asdict(incident) for incident in self.active_incidents.values()],
            "threat_intelligence": await self.get_threat_intelligence(),
            "performance_metrics": {
                "avg_event_processing_time_ms": statistics.mean(self.performance_metrics["event_processing_times"]) if self.performance_metrics["event_processing_times"] else 0,
                "avg_query_response_time_ms": statistics.mean(self.performance_metrics["query_response_times"]) if self.performance_metrics["query_response_times"] else 0,
                "avg_anomaly_detection_time_ms": statistics.mean(self.performance_metrics["anomaly_detection_times"]) if self.performance_metrics["anomaly_detection_times"] else 0
            }
        }
        
        # Track query performance
        query_time = (time.time() - start_time) * 1000
        self.performance_metrics["query_response_times"].append(query_time)
        
        return report

# Main function for demonstration
async def main():
    """Demonstration of the Security Monitoring Dashboard."""
    dashboard = SecurityMonitoringDashboard()
    
    try:
        print(" Starting ALCUB3 Security Monitoring Dashboard...")
        
        # Start monitoring in background
        monitoring_task = asyncio.create_task(dashboard.start_monitoring())
        
        # Let it run for a short time to collect some data
        await asyncio.sleep(10)
        
        # Query dashboard data
        print("\n Security Metrics:")
        metrics = await dashboard.get_security_metrics()
        print(json.dumps(metrics, indent=2, default=str))
        
        print("\n Recent Events:")
        recent_events = await dashboard.get_recent_events(limit=10)
        print(f"Found {len(recent_events)} recent events")
        
        print("\n Active Incidents:")
        incidents = await dashboard.get_active_incidents()
        print(f"Found {len(incidents)} active incidents")
        
        print("\n Threat Intelligence:")
        threat_intel = await dashboard.get_threat_intelligence()
        print(json.dumps(threat_intel, indent=2, default=str))
        
        print("\n Security Report:")
        report = await dashboard.export_security_report(timeframe_hours=1)
        print(f"Generated report with {report['report_metadata']['total_events']} events")
        
        # Stop monitoring
        await dashboard.stop_monitoring()
        
        print("\n Security Monitoring Dashboard demonstration completed!")
        
    except Exception as e:
        print(f" Error: {e}")
        await dashboard.stop_monitoring()

if __name__ == "__main__":
    asyncio.run(main())